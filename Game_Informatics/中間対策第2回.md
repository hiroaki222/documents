**問題 1**

教師あり学習の主な目的として，最も適切な記述を選んでください．

1 つ選択してください:

1. 与えられた学習データセット内のパターンや構造を発見すること．
2. 未知のデータに対して正確な予測や分類を行うモデルを構築すること．
3. データを類似性に基づいてグループ化（クラスタリング）すること．
4. 試行錯誤を通じて最適な行動方策を学習すること．

<details>
<summary>解答解説を表示</summary>
2

**解説:**
教師あり学習の真の目的は，学習時に与えられたデータ（学習データ）を再現することではなく，学習時には与えられていない未知のデータに対して高い性能（汎化性能）を発揮するモデルを構築することです (p.7)．選択肢 1 や 3 は主に教師なし学習の目的であり，選択肢 4 は強化学習の目的です (p.2)．

</details>

---

**問題 2**

機械学習における「過学習（Overfitting）」について，最も適切な説明を選んでください．

1 つ選択してください:

1. モデルが単純すぎて，学習データの特徴を十分に捉えられない状態．
2. モデルが複雑すぎて，学習データに含まれるノイズまで学習してしまい，未知のデータに対する性能（汎化性能）が悪化する状態．
3. 学習データが少なすぎて，モデルの学習が十分に進行しない状態．
4. 学習に時間がかかりすぎて，実用的な時間内に学習が完了しない状態．

<details>
<summary>解答解説を表示</summary>
2

**解説:**
過学習とは，モデルが学習データに過剰に適合してしまい，学習データに対する性能（学習性能）は高いものの，未知のデータに対する性能（汎化性能）が低くなってしまう現象を指します (p.7, p.9-10)．これはモデルが複雑すぎる場合に起こりやすいです (p.10)．選択肢 1 は「学習不足（Underfitting）」と呼ばれる状態です．

</details>

---

**問題 3**

モデルの複雑さと性能の関係について，一般的な傾向として最も適切な記述を選んでください．

1 つ選択してください:

1. モデルが複雑になるほど，学習性能と汎化性能はともに向上し続ける．
2. モデルが単純すぎると学習性能は低いが，汎化性能は最も高くなる．
3. モデルの複雑さが「適度」な場合に，汎化性能が最も高くなることが多い．
4. モデルの複雑さは，学習性能や汎化性能にほとんど影響を与えない．

<details>
<summary>解答解説を表示</summary>
3

**解説:**
一般的に，モデルが単純すぎると学習データの特徴を捉えきれず学習性能も汎化性能も低くなります．逆にモデルが複雑すぎると，学習データにはよく適合する（学習性能は高い）ものの過学習を起こしやすく，汎化性能は低下します．そのため，学習性能と汎化性能のバランスが取れた「適度な」複雑さのモデルが，最も良い汎化性能を示すことが多いとされています (p.10)．ただし，近年の研究では，特定の条件下で非常に複雑なモデル（パラメータ数が多いニューラルネットワークなど）が高い汎化性能を示す「二重降下（Double Descent）」現象も観測されています (p.11)．

</details>

---

**問題 4**

学習データ数を増やすことの効果として，一般的な傾向として適切な記述を選んでください．

1 つ選択してください:

1. 学習データ数を増やすと，学習性能は向上し，汎化性能は低下する．
2. 学習データ数を増やすと，学習性能は低下し，汎化性能は向上する．
3. 学習データ数を増やすと，学習性能も汎化性能もともに向上する．
4. 学習データ数を増やすと，学習性能も汎化性能もともに低下する．

<details>
<summary>解答解説を表示</summary>
2

**解説:**
学習データ数を増やすと，モデルはより多様なパターンを学習する必要が出てくるため，特定の学習データセットに対する適合度（学習性能）は低下する傾向があります（より一般的なパターンを学習するため）．一方で，より多くのデータに基づいて学習することで，未知のデータに対する予測能力（汎化性能）は向上する傾向があります (p.11)．したがって，質が保たれる限り，学習データは多い方が良いとされます．

</details>

---

**問題 5**

2 値分類問題において，「病気の可能性がある人を正例（Positive）」と定義します．このとき，「実際には病気でない人を誤って病気であると判定してしまう」ケースは何と呼ばれますか．

1 つ選択してください:

1. True Positive (真陽性)
2. False Positive (偽陽性)
3. True Negative (真陰性)
4. False Negative (偽陰性)

<details>
<summary>解答解説を表示</summary>
2

**解説:**
False Positive（偽陽性）は，実際には陰性（Negative, この場合は病気でない）であるものを，誤って陽性（Positive, 病気の可能性がある）と判定してしまうケースを指します (p.13)．False Negative（偽陰性）はその逆で，実際には陽性（病気の可能性がある）であるものを見逃してしまう（陰性と判定する）ケースです．どちらの誤りがより深刻かは，問題の状況によって異なります (p.13)．

</details>

---

**問題 6**

食中毒を引き起こす可能性のある毒キノコを見分ける分類器を作成する場合，特に避けたい誤りはどれですか．「食べられるキノコを正例（Positive）」と定義します．

1 つ選択してください:

1. True Positive (真陽性): 食べられるキノコを正しく食べられると判定する．
2. False Positive (偽陽性): 毒キノコを誤って食べられると判定する．
3. True Negative (真陰性): 毒キノコを正しく毒キノコと判定する．
4. False Negative (偽陰性): 食べられるキノコを誤って毒キノコと判定する．

<details>
<summary>解答解説を表示</summary>
2

**解説:**
このシナリオで最も避けたいのは，毒キノコを誤って「食べられる（正例）」と判定してしまうことです．これは健康に深刻な影響を与える可能性があるためです．定義に従うと，これは実際には陰性（毒キノコ）であるものを陽性（食べられる）と誤判定する「False Positive（偽陽性）」に該当します (p.13)．False Negative（食べられるキノコを毒キノコと誤判定する）は機会損失にはなりますが，直接的な健康被害は引き起こしません．

</details>

---

**問題 7**

決定木（Decision Tree）に関する記述として，最も適切なものを選んでください．

1 つ選択してください:

1. Nearest Neighbor 法と同様に，学習データをすべて保持し，予測時に参照する Lazy Learning の手法である．
2. 主に連続値の予測（回帰問題）に用いられ，離散値の分類には適さない．
3. If-Then 形式のルール集合として表現でき，人間にとって解釈しやすいという利点がある．
4. ニューラルネットワークと比較して，常に高い汎化性能を発揮する．

<details>
<summary>解答解説を表示</summary>
3

**解説:**
決定木は，データを条件分岐（If-Then ルール）によって段階的に分類していくモデルです (p.17)．その構造はフローチャートに似ており，人間にとってモデルの判断根拠が理解しやすいという特徴があります (p.17)．決定木は事前に学習を行う Eager Learning であり（選択肢 1 は誤り），主に離散的な入出力（分類問題）に用いられます（選択肢 2 は逆） (p.17)．性能は問題やデータに依存し，常にニューラルネットワークより優れているわけではありません（選択肢 4 は誤り）．

</details>

---

**問題 8**

決定木の学習において，あるノードでデータを分割する際に最も重視される基準は何ですか．

1 つ選択してください:

1. 分割後のデータ数が均等になること．
2. 分割によって，各グループ内のデータのクラスが可能な限り均一（不純度が低い状態）になること．
3. 使用する特徴量の数が最小になること．
4. 決定木の深さが最も浅くなること．

<details>
<summary>解答解説を表示</summary>
2

**解説:**
決定木の学習では，データを分割する際に「どの条件（特徴量とその閾値）で分割すると，最も情報が整理されるか」を考えます (p.20)．これは，分割後の各グループができるだけ単一のクラス（例：すべて正例，またはすべて負例）に近づくように，つまり不純度が低くなるように分割することを意味します．この「整理度合い」を定量化するためにエントロピーやジニ不純度といった指標が用いられ，それらが最も減少する（= Information Gain が最大になる）分割が選ばれます (p.21-22)．

</details>

---

**問題 9**

あるデータセット S が，正例(o) 4 個と負例(x) 4 個で構成されているとします（S = {oooo, xxxx}）．このデータセットのエントロピーを計算してください．ただし，log2(0.5) = -1 とします．

1 つ選択してください:

1. 0
2. 0.5
3. 0.811
4. 1

<details>
<summary>解答解説を表示</summary>
4

**解説:**
エントロピーは，2 値分類の場合，Entropy = -p+ log2(p+) - p- log2(p-) で計算されます (p.21)．ここで p+ は正例の割合，p- は負例の割合です．
このデータセットでは，正例の割合 p+ = 4 / (4+4) = 0.5，負例の割合 p- = 4 / (4+4) = 0.5 です．
よって，Entropy = -0.5 _ log2(0.5) - 0.5 _ log2(0.5) = -0.5 _ (-1) - 0.5 _ (-1) = 0.5 + 0.5 = 1 となります．
エントロピーは，クラスが最も混在している状態（割合が 0.5）のときに最大値 1 をとります (p.21)．

</details>

---

**問題 10**

あるデータセット S {ooooxxx} を特徴 A で分割したところ，S1 {ooo} と S2 {oxxx} の 2 つのグループに分かれました．分割前のエントロピー Entropy(S)は約 0.985，S1 のエントロピー Entropy(S1)は 0 です．S2 のエントロピー Entropy(S2)が約 0.811 であるとき，特徴 A による分割の Information Gain（情報利得）を計算してください．

1 つ選択してください:

1. 0
2. 0.174
3. 0.522
4. 0.985

<details>
<summary>解答解説を表示</summary>
3

**解説:**
Information Gain は，分割前のエントロピーから，分割後の各グループのエントロピーの加重平均を引いた値で計算されます (p.22)．
Gain = Entropy(S) - (|S1|/|S| _ Entropy(S1) + |S2|/|S| _ Entropy(S2))
ここで，|S|=7, |S1|=3, |S2|=4 です．
Gain = 0.985 - (3/7 _ 0 + 4/7 _ 0.811)
Gain = 0.985 - (0 + 4/7 _ 0.811)
Gain ≈ 0.985 - (0.571 _ 0.811)
Gain ≈ 0.985 - 0.463
Gain ≈ 0.522
これはスライド p.22 の計算例と同じです (p.22)．

</details>

---

**問題 11**

k-Nearest Neighbor (k-NN) 法に関する記述として，最も適切でないものを選んでください．

1 つ選択してください:

1. 距離計算を行うため，入力データが離散的な値（カテゴリ変数など）の場合，そのままでは適用が難しい場合がある．
2. 学習データが多い場合や k の値が大きい場合，予測時の計算コストが高くなる可能性がある．
3. 決定木と同様に，事前に学習フェーズでモデルを構築する Eager Learning の手法である．
4. k=1 の Nearest Neighbor 法は，学習データのノイズの影響を受けやすい．

<details>
<summary>解答解説を表示</summary>
3

**解説:**
k-NN 法は，学習データをそのまま保持し，予測要求があった時点（実行時）に近傍のデータを探して予測を行う「Lazy Learning（怠惰学習）」に分類されます (p.3)．事前にモデルを構築する「Eager Learning（熱心学習）」ではありません．他の選択肢は k-NN 法の特徴として正しいです．距離計算が基本なので離散入力は工夫が必要であり (p.3)，データ数や k が増えると計算量が問題になり (p.4)，k=1 の場合はノイズに弱いとされています (p.4)．

</details>

---

**問題 12**

機械学習モデルの性能評価のためにデータを分割する際，「検証（Validation）データ」は主にどのような目的で使用されますか．

1 つ選択してください:

1. モデルの最終的な汎化性能を評価するため．
2. モデルの学習（パラメータ調整）を行うため．
3. 学習中にモデルのハイパーパラメータ（例：k-NN の k の値，決定木の深さ制限など）を調整したり，過学習を検知（例：Early Stopping）したりするため．
4. 学習データに含まれるノイズを除去するため．

<details>
<summary>解答解説を表示</summary>
3

**解説:**
学習データはモデルのパラメータ学習に用いられます．検証データは，学習中にモデルの性能を監視し，過学習の兆候が見られた場合に学習を早期に打ち切る（Early Stopping）判断や，k-NN における k の値，ニューラルネットワークの層数やノード数といったハイパーパラメータの最適な値を決定するために使用されます (p.12)．最終的なモデルの汎化性能は，学習にも検証にも用いられなかった「テストデータ」で評価するのが一般的です (p.12)．

</details>

---

**問題 13**

不均衡なデータセット（例：正例が非常に少なく，負例が非常に多い）に対してクラス分類を行う際の問題点として，最も適切なものを選んでください．

1 つ選択してください:

1. モデルの学習時間が極端に長くなる．
2. 決定木モデルを構築することができなくなる．
3. 単純に一致率（Accuracy）を最大化しようとすると，全てのデータを多数派クラスに分類するモデルが選ばれてしまう可能性がある．
4. 過学習が発生しにくくなる．

<details>
<summary>解答解説を表示</summary>
3

**解説:**
不均衡なデータセットでは，例えば 99%が負例で 1%が正例の場合，すべてのデータを「負例」と予測するだけで 99%の一致率が得られてしまいます (p.15)．これは見かけ上高い性能ですが，少数派クラス（この場合は正例）を全く検出できていないため，実用上問題となることが多いです．このような場合，一致率以外の評価指標（例：適合率，再現率，F 値など）を用いたり，データへの重み付けやサンプリング手法（オーバーサンプリング，アンダーサンプリング）を工夫したりする必要があります (p.15)．

</details>

---

**問題 14**

スライド p.18 の将棋の例において，「駒の動かし方」を知っているか否かでデータを分割した場合，それぞれのグループの初心者/初心者でない人の構成はどうなりますか．

1 つ選択してください:

1. 「知ってる」グループ: {No, Yes, No, No}, 「知らない」グループ: {Yes, Yes, Yes}
2. 「知ってる」グループ: {No, No, No}, 「知らない」グループ: {Yes, Yes, Yes, Yes}
3. 「知ってる」グループ: {No, Yes, No, Yes}, 「知らない」グループ: {Yes, No, Yes}
4. 「知ってる」グループ: {Yes, Yes, Yes}, 「知らない」グループ: {No, No, No, No}

<details>
<summary>解答解説を表示</summary>
1

**解説:**
スライド p.18 の表から，「駒の動かし方」列と「初心者か」列を確認します (p.18)．
「知ってる」行（飯田，鈴木，渡辺，本田）の「初心者か」列は {No, Yes, No, No} です．
「知らない」行（佐藤，田中，山本）の「初心者か」列は {Yes, Yes, Yes} です．
したがって，選択肢 1 が正しい分割結果を示しています．

</details>

---

**問題 15**

エントロピーが 0 になるのはどのような状態ですか．最も適切な記述を選んでください．

1 つ選択してください:

1. データセット内の正例と負例の数が等しいとき．
2. データセット内のすべてのデータが同じクラスに属しているとき（例：すべて正例，またはすべて負例）．
3. データセットのサイズが非常に大きいとき．
4. 決定木の分割が不可能になったとき．

<details>
<summary>解答解説を表示</summary>
2

**解説:**
エントロピーはデータの「乱雑さ」や「不純度」を表す指標です (p.20-21)．もしデータセット内のすべてのサンプルが同じクラスに属していれば，そのデータセットは完全に「整理された」状態であり，不純度はゼロです．このとき，エントロピーの計算式 Entropy = -p+ log2(p+) - p- log2(p-) において，p+か p-のどちらかが 1 で他方が 0 となり，lim(p→0) p log2(p) = 0 であることから，エントロピーは 0 になります (p.21)．正例と負例が半々のときはエントロピーが最大（1）になります (p.21)．

</details>
